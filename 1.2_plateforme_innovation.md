---
auteur: Arthur Sarazin
number_sections: TRUE
output: pdf_document
---

## 1.2 Le rôle et la place des plateformes de services dans les smart city

 Résumé | 
------------ | 
Lorem ipsum | 


#### Définition d'une plateforme de services selon Pitt et al. (2017) : un lieu virtuel au croisement entre les systèmes cyber-physiques et socio-techniques.

Un système cyber-physique intègre des objets informatiques (ex : caméras, capteurs)  et des artefacts matériels (ex : ordinateurs, serveurs) dans le but de capter, d’analyser et d’exploiter des données sur un espace physique (ex : une ville). Parmi les nombreux exemples de tels systèmes, décrivons le système de localisation du Syndicat Mixte de Transports en Commun (SMTC) de la ville de Grenoble. Chaque bus et tram de la ville possède des capteurs qui permettent de les géolocaliser. Ces données sont collectées par des serveurs appartenant à la métropole grenobloise qui, grâce à elles, peut organiser et gérer les transports communs de la ville en temps réel. 

Un système socio-technique se définit comme le point de rencontre entre d’un côté des individus, organisations, institutions, communautés et sociétés, et de l’autre, des machines et technologies. L’Open lab La Péniche à Grenoble constitue un système socio-technique à part entière dans la mesure où il rassemble les parties prenantes de l’Open data au sein de lieux physiques et virtuels et met à disposition des machines et technologies permettant de créer des services issus des données. 

#### La place centrale de la plateforme de services dans la smart city : regard de la service-dominant logic (Lusch et Nambisan, 2015) 

La service-dominant logic est un cadre conceptuel selon lequel la smart city est constituée de 3 éléments (Lusch et Nambisan, 2015)  : 

- un écosystème de services défini comme un système relativement autonome et autorégulé composé d'acteurs sociaux et économiques faiblement liés, reliés par des logiques institutionnelles partagées et une création de valeur mutuelle via l'échange de services. 
- une plateforme de services définie comme une structure modulaire composée d’éléments tangibles et intangibles qui facilite l'interaction des acteurs et des ressources.
- la co-création de valeur qui se comprend comme les processus et activités qui sous-tendent l'intégration des ressources et intègrent différents rôles d'acteur dans l'écosystème de services.

Prenant appui sur ces éléments, nous pouvons définir la smart-city comme un écosystème de services qui se construit autour d’une plateforme de services dans le but de co-créer de la valeur. Au coeur de cette définition se trouve le concept de plateforme de services. 

Au croisement entre l’écosystème et la co-création de valeur, la plateforme de service permet dans un premier temps de centraliser les nombreuses ressources détenues par chaque membre de l’écosystème ou,  pour reprendre les termes les termes de Lusch et Nambisan (2015, p. 157), de “maximiser leur densité”.  Dans un deuxième temps, la plateforme facilite la dynamisation des échanges de ressources entre les membres de l’écosystème de la Smart City. Autrement dit, elle augmente la liquidité des ressources.  Enfin, forte d’une densité importante de ressources liquides, la plateforme constitue le lieu d’élection pour développer des mécanismes de co-création de services entre les membres de l’écosystème. 

Etant donné la place centrale qu’occupe la plateforme dans la co-création de services, nous étudierons dans les parties suivantes, les dimensions des plateformes de services ayant une influence sur la co-création de services. 

#### Le rôle clé des plateformes de services dans la smart city : un vecteur d’innovation ouverte de services

La capacité d’une plateforme de services à générer de l’innovation de services dépend de 3 caractéristiques : son architecture, la capacité d’évolution de l’architecture et sa license d’utilisation. 

L’architecture d’une plateforme se définit comme le schéma conceptuel décrivant les composants stables et homogènes de la plateforme, les modules hétérogènes qui gravitent autour de ces composants, et les règles de design qui régissent l’articulation entre ces deux éléments (Tiwana et al., 2010). L’architecture d’une plateforme possède des fonctions primaires qui constituent le coeur de la valeur d’une plateforme ainsi que des fonctions secondaires (dites “ilités”) dont la valeur varie en fonction du cycle de vie de la plateforme : durabilité, maintenabilité, flexibilité, etc.  

Pour qu’une plateforme se maintienne et se développe, elle doit intégrer des modules de plus en plus hétérogènes sans pour autant détériorer les composants stables qui permettent les agencements entre ces derniers. Cette dialectique constitue à la fois le moteur du développement des plateformes et la principale problématique pour les architectes des plateformes qu’ils résolvent grâce à un certain nombre de règles de design.  

Une des caractéristiques critiques d’une plateforme réside dans sa license d’utilisation (Pitt et al., 2017). On distingue principalement les plateformes sous licence propriétaire, détenues par un seul acteur dont l’accès est conditionné par le paiement d’une redevance ou par le consentement à voir ses données personnelles utilisées et les plateformes sous license ouverte, dont l’accès est gratuit et dont le code source peut être modifié par toutes les personnes y voyant un intérêt. Le choix d’une license propriétaire ou ouverte est crucial dans la mesure où il influence la manière dont les parties prenantes échangent des ressources. Plus précisément, une plateforme sous license propriétaire amène à une asymétrie dans la distribution des ressources qui peut inhiber l’action collective issue des échanges entre les membres de l’écosystème et donc la co-création de service. A l’inverse, une plateforme sous license ouverte facilite la distribution de ressources, démocratise son utilisation au profit de mécanismes de co-création de services plus participatifs. 

#### Les mécanismes de gouvernance génériques des plateformes de services 

Les mécanismes de gouvernance d’une plateforme correspondent aux processus mis en place pour administrer les opérations des deux côtés de la plateforme et maintenir son écosystème (Tiwana et al., 2010). En effet, comme l’indique le schéma ci-dessous tiré d’Eisenmann et al. (2008), une plateforme se positionne comme un intermédiaire entre deux types d’utilisateurs : les fournisseurs de modules hétérogènes d’un côté (offre) et de l’autre les bénéficiaires de ces modules (demande). 

![Schéma de gouvernance générique d'une plateforme](http://opendatatales.com/wp-content/uploads/2020/03/Screen-Shot-2020-02-29-at-23.59.54.png)
##### Figure 4 : éléments de l’écosystème d’une plateforme selon Eisenmann et al. (2008)

Le design de mécanismes de gouvernance permet à l’opérateur de la plateforme de stimuler l’adaptabilité et la résilience de l’écosystème en incorporant la connaissance qu’il possède des interdépendances et de la co-évolution entre les deux types d’utilisateurs. (Allen and Varga, 2006 ; Benbya and McKelvey, 2006 ; Tanriverdi et al., 2010)

A terme, le design de ces mécanismes tend vers un équilibre permettant de garder suffisamment de contrôle sur le développement de l’écosystème pour assurer l’intégrité de la plateforme tout en laissant des zones de liberté aux acteurs et utilisateurs. Ceci afin qu’ils puissent innover au travers de la création de nouveaux modules hétérogènes venant s’incorporer à la plateforme. 
	
Tiwana et al. (2010) identifie trois approches théoriques distinctes pour expliquer la gouvernance des plateformes : la gouvernance par le partage de l’autorité et des responsabilités (approche centrée autour de la répartition du pouvoir de décision), la gouvernance par l’alignement des intentions (approche centrée autour des démarches de contrôle) et la gouvernance par le partage de l’intérêt (approche centrée autour de la propriété de la plateforme). 

Selon l’approche de la gouvernance par le partage de l’autorité et des responsabilités, la gouvernance des plateformes doit répondre à trois questions et par les réponses apportées diviser l’autorité et la responsabilité entre les propriétaires de la plateforme et les développeurs de modules : 
- quelle est la finalité de chaque sous-ensemble de la plateforme ? 
- comment ce sous-ensemble devrait-il faire ce qu’il fait ? 
- qui contrôle les interfaces internes (i.e, les éléments qui définissent les frontières des modules) de l’écosystème ? 

Selon l’approche de la gouvernance par l’alignement des intentions, la gouvernance d’une plateforme vise à mettre en place des mécanismes formels et informels visant à encourager des comportements souhaitables chez les développeurs de modules. Le contrôle formel peut prendre deux formes : 
Le contrôle de résultat par lequel le propriétaire de la plateforme précise les critères d’évaluation des modules développés 
Le contrôle du process par lequel le propriétaire de la plateforme flèche des méthodes et procédures aux développeurs de module. 

Enfin, selon l’approche de la gouvernance par le partage des intérêts, la gouvernance de la plaforme revient à distribuer les droits de la propriété de la plateforme et d’établir dans quelle mesure la propriété est partagée entre plusieurs acteurs (Eisenmann et al., 2006)

#### Les mécanismes de gouvernance de plateformes spécifiques aux smart city

Selon Lusch et Nambisan (2015), Il existe 3 types de parties prenantes investies dans les plateformes de services : les architectes, les acteurs et les bénéficiaires.

![Parties prenantes des plateformes smart city](http://opendatatales.com/wp-content/uploads/2020/03/Screen-Shot-2020-03-01-at-00.08.31.png)
##### Figure 5 : typologie des parties prenantes impliquées dans les mécanismes de gouvernance de la plateforme de services des Smart city.

Selon Lusch et Nambisan (2015), Il existe 3 types de parties prenantes investies dans les plateformes de services : les architectes, les acteurs et les bénéficiaires.

Les architectes créent l’architecture de participation qui clarifie la façon dont la co-création de valeur se déroule et la façon dont cette valeur est répartie entre les acteurs. Autrement dit, ils mettent en place une road map stratégique, soit une direction à suivre par tous les acteurs impliqués dans l’écosystème de services. Aussi créent-ils les mécanismes de gouvernance permettant de piloter le fonctionnement et l’évolution de l’écosystème de services vers les objectifs fixés par la road map stratégique. 

Les acteurs ont, de leur côté, les moyens techniques et les compétences pour exploiter les ressources présentes sur la plateforme dans le but de co-créer des services. Ils peuvent occuper trois rôles : idéateur, designer et intermédiaire. Les idéateurs apportent des connaissances sur l’écosystème, ses besoins et les offres de services existantes. Les designers créent des services à partir de nouvelles configurations de ressources. Enfin, les intermédiaires créent des synergies entre les différentes parties de l’écosystème. Ces acteurs constituent les premiers utilisateurs des mécanismes de gouvernance et participent à leur construction dans le cas des plateformes ouvertes.

Enfin, les bénéficiaires font l’expérience de la valeur créée par les services selon 4 types d’expériences : l’expérience pragmatique, l’expérience socialisante, l’expérience d’usage et l’expérience hédonique (Nambisan & Nambisan, 2008). Cette valeur se matérialise finalement pour les bénéficiaires par une amélioration de leur qualité de vie.  

#### Origines du manque d'implication des villes dans la réutilisation des données ouvertes et émergence de politiques de réutilisation

 Résumé | 
------------ | 
Dans cette partie, il sera question tout d’abord de pointer du doigt le postulat implicite à l’origine du du manque d’implication des villes dans la réutilisation de leurs données ouvertes avant de reprendre les catégories de politiques de réutilisation instaurées par Courmont (2016). Nous visons ici à développer plus en profondeur l’idée évoquée dans la partie précédente selon laquelle les acteurs publics rencontrent de nombreuses difficultés pour faciliter la réutilisation des données en open data, quand ils ne laissent pas complètement cet aspect hors de leur agenda | 

**Manque d'implication des villes dans la réutilisation des données ouvertes**
A l’origine du mouvement de l’open data on retrouve l’idée selon laquelle une fois les données mises en open data, elles seraient réutilisées et transformées en innovation, avec à la clé de la création de valeur économique (Chignard, 2013). On trouve ce postulat pour la première fois dans un rapport de la commission européenne de 2006, intitulé Measuring European Public Sector Information Resources (Dekkers et al., 2006) et qui estime que l’open data et les informations publiques pourraient créer un marché estimé à 40 milliards d’euros par an. 

Nous décrirons ici la logique construite par la commission européenne pour venir supporter cette estimation (figure ci-dessous).

![Logigramme](http://opendatatales.com/wp-content/uploads/2020/03/Document-de-travail-Revue-de-littérature-Mars-2019.png)
##### Figure 6. logigramme établissant le lien entre l’offre de données, la demande de données et les résultats économiques de l’open data (Dekkers et al., 2006)

En premier lieu, la commission européenne identifie trois rôles que les organisations impliquées dans l’open data peuvent jouer : 

1. Fournisseur public de données : tout organismes public ou organisme régit par le droit public qui fournit des données à un marché. 
2. Réutilisateur de données : les organismes (hors secteur public) qui fournissent de l’information au marché. 
3. Utilisateur : toute personne ou organisation utilisant les informations fournies par les réutilisateurs. 

Puis, elle articule les relations entre ces rôles en suivant une logique constituée de 5 conditions cadres, et de 2 types d’impact économiques. Les premières correspondent à des principes généraux s’appliquant à l’offre de données et d’informations tandis que les seconds ont traits aux conséquences économiques de l’application des principes généraux (description ci-dessous) 

<table>
<tr>
<td rowspan= "5">Conditions cadres</td>
<td>1.Si les données ne sont pas disponibles pour les réutilisateurs alors il n’y aura pas de marché  </td>
</tr>
<tr>
<td>2. Si les données disponibles ne sont pas accessibles, alors il ne peut y avoir de réutilisations </td>
</tr>
<tr>
<td>3. Si les conditions de réutilisation des données ne sont pas transparentes, alors l’accessibilité perd tout son sens et il ne pourra y avoir de marché lié à la réutilisation des données </td>
</tr>
<tr>
<td>4. Les producteurs de données sont responsables et doivent rendre des comptes vis à vis des 3 premiers points</td>
</tr>
<tr>
<td>5. Les 4 premiers points doivent être respectés et ce, quelque soit le réutilisateur </td>
</tr>
<tr>
<td rowspan= "5">Impacts économiques</td>
<td>6. L’égalité et l’équité face aux données/informations publiques stimulera la demande actuelle de données et d’informations </td>
</tr>
<tr>
<td>7. Cette demande se traduira éventuellement par des résultats économiques directs (plus de chiffre d’affaire pour les réutilisateurs) et indirecteurs (plus d’activités commerciales basées sur la réutilisation des informations publiques)  </td>
</tr>

</table>

En substance, la commission européenne estime que si les producteurs de données ouvertes font en sorte que ces données soient disponibles (point 1), accessibles (point 2), transparentes (point 3), que les fournisseurs de données s’engagent à rendre des comptes (point 4) et à fournir un accès égal et équitable à tous (point 5 et point 6), alors les données seront d’avantage réutilisées. Autrement dit, la commission européenne suggère que les acteurs publics verront leurs données réutilisées naturellement si elles respectent ces 5 critères. 

Ce raisonnement, que je rangerai ici parmi les fondations intellectuelles de l’open data, peut participer à expliquer l’avènement du mythe d’un développement économique causé, presque naturellement, par l’ouverture des données publiques. Aussi permet-il de comprendre la posture historique des politiques open data, qui allouent peu de moyens aux pratiques qui pourraient accroitre durablement la réutilisation des données ouvertes. Enfin, l’intérêt tardif de la communauté scientifique et le faible nombre d’études s’intéressant à la réutilisation peut être perçu comme une autre conséquence de ce raisonnement fondateur. Et Courmont (2016, p.242) de résumer : “l’accent est d’avantage mis sur l’accès aux données que sur les usages qui en sont faits” 

**L'émergence de politiques de réutilisation**
Pour pallier à ce manque de matériau scientifique, Courmont (2016) a réalisé une quinzaine d’études de cas de réutilisations de données mises à disposition par le Grand Lyon. A partir d’elles, il a pu établir 3 catégories de politiques de réutilisation. Rappellons ici qu’il conçoit une politique de données en se basant sur les travaux de Bruno Latour et qu’il définit comme : “l’ensemble des opérations de compositions de collectifs autour des données”. Cette conception a l’avantage de ne pas restreindre les politiques de données aux politiques telles que conçues par les sciences politiques : “Ces politiques de données peuvent s’inscrire dans ce qui relève d’un champ politique, mais elles ne s’y restreignent pas. Il existe autant de politiques qu’il y a d’étapes dans les transformations de données” (Courmont, 2016, p.31)

Suivant cette conception, il distingue 3 catégories de politique de données en suivant 3 étapes de transformation de la donnée : la consolidation, l’homogénéisation et l’articulation. 

1. Les politiques de consolidation

Ces politiques sont mises en place pour contrer le risque de deliquescence des données une fois qu’elles ont été extraites de leur univers institutionnel d’origine. Comme une plante qui une fois déracinée dépérit, la donnée perd de son potentiel de réutilisation une fois extraite de son contexte de production. 
Les politiques de consolidation visent à renforcer “la capacité de la donnée à resister à des circonstances et pratiques inattendues” (Courmont, 2016, p.247), et ce en ajoutant des éléments qui vont faciliter le passage de la donnée d’un contexte à un autre. Parmi les mesures liée à ce type de politique, nous pouvons prendre l’exemple du renseignement des métadonnées. Celles-ci donnent des indications textuelles sur ce que contient le jeu de données, la période et l’objet couvert. Avec ces informations, un réutilisateur peut facilement estimer la valeur de l’usage de ce jeu de données dans son contexte et univers social. 

2. Les politiques d'homogénéisation

Ces politiques sont mises en place lorsque les acteurs souhaitent utiliser les données dans une dimension plus large que celle pour laquelle elles ont été produites. Dans le cadre des villes, il peut s’agir de passer de l’échelle communale à l’échelle métropolitaine. L’avantage de cette homogénéisation est de pouvoir trouver des conventions communes s’appliquant à des données hétérogènes permettant de les intégrer pour pouvoir ensuite développer des services à un échelon spatial ou institutionnel supérieur. 
Ces politiques d’homogénéisation sont souvent mises en place par des acteurs hors de la sphère publique. Nous pouvons citer OpenStreetMap qui récupère et homogénéise les données géographiques ouvertes pour proposer un Wikipédia de la géographie à l’échelle mondiale.

3. Les politiques d'articulation

Ce type de politique consiste à mettre en relation des données qui ne sont pas du même type en trouver un dénominateur commun. Ces politiques sont mises en place quand les données produites rentrent dans la catégorie des big data, entendu au sens où la quantité générée est extrêmement importante avec des types de données extrêmement divers. En effet, pour pouvoir utiliser ces immenses quantités de données hétérogènes, il faut être capable de les relier entre elles.
Cette politique a notamment été mise en place par la Centrale de mobilité du Grand Lyon, pour “articuler les données de l’ensemble des modes de transport de l’agglomération lyonnaise pour produire une représentation métropolitaine de la mobilité (Courmont, 2016, p.294)

#### Caractéristiques des innovations de services issues de l'open data

 Résumé | 
------------ | 
Dans cette sous-partie, nous recensons toutes les barrières à la réutilisation des données ouvertes identifiée jusque là dans la littérature et qui expliquent les rares innovations issues de l’open data en France aujourd’hui.| 

**De rares innovations du fait de nombreuses barrières empêchant la réutilisation des données ouvertes**

- Distinguer l’utilisation de la réutilisation des données 

Selon Haefliger et al. (2008), on retrouve le concept de réutilisation principalement dans la littérature sur l’innovation technologique. Celle-ci s’est attachée principalement à décrire la réutilisation de codes informatiques dans l’industrie du logiciel open source. Le système d’exploitation Linux ou le moteur de navigation Firefox sont par exemple constitués d’une multitude de lignes de codes ayant déjà été créés pour d’autres projets et ensuite adaptés pour leurs propres besoins par les développeurs de ces logiciels. C’est cette pratique que nous nommons réutilisation dans cette partie.

Cette pratique est un moyen pour les développeurs de logiciels d’économiser des ressources et du temps et donc de réduire le cout de production de nouveaux logiciels. Au lieu de programmer un logiciel dans son ensemble, ils agrègent des composantes déjà existantes, gagnant ainsi un temps précieux. Par exemple, pour les logiciels ayant besoin de lire des images, photos ou vidéos, un développeur pourra réutiliser une des librairies du projet FFmpeg qui contiennent les codes nécessaires pour mettre en place cette fonctionnalité. 

Avec Haefliger et al. (2008), les facteurs amenant des développeurs de logiciels open source à faire le choix de réutiliser des connaissances au lieu d’en créer ex nihilo ont été identifiés. 
En premier lieu, le choix de réutiliser des connaissances est déterminé par le rapport entre le cout de recherche et d’intégration de codes existants par rapport à celui d’écrire entièrement le code. Lorsqu’il est très difficile de trouver les connaissances adéquat du fait de l’absence d’outils de recherche et de standards robustes, les développeurs auront plutôt tendance à se lancer dans la programmation de nouveaux codes. 
La documentation et les standards de qualité facilitent aussi grandement la réutilisation de composants logiciels. Avec une description précise, un développeur pourra rapidement décider si le composant proposé convient au projet qu’il développe. Aussi, si la qualité d’un composant logiciel est certifiée par l’utilisation de certains standards, un développeur aura plus tendance à réutiliser ce composant, sachant qu’il y a peu de risques qu’il soit à l’origine de bugs. 
Les facteurs de motivation jouent un rôle crucial dans les programmes de réutilisation. Qu’ils soient basés sur la rémunération ou sur la réputation, ces facteurs doivent être suffisamment importants pour éclipser l’idée que la réutilisation de codes est moins excitante que celle de créer de nouveaux. 
Enfin, il faut qu’une base suffisamment étendue de précédents de réutilisation soient disponibles pour que les développeurs considèrent que les composantes mis à disposition constituent une “promesse crédible” (Haefliger et al., 2008). 

Dans cette thèse, je pose l’hypothèse que les facteurs qui stimulent la réutilisation de codes informatiques peuvent s’appliquer à la réutilisation de jeux de données ouverts ainsi qu’à l’ensemble des artefacts qui permettent de faciliter cette même réutilisation dans le cadre des smart cities. Cette hypothèse me semble crédible dans la mesure où la littérature sur la réutilisation des codes informatique a statué qu’au-delà de sa particularité technique, le code informatique était une forme de connaissance particulière. Dès lors, cette littérature a mis en avant que les principes de la réutilisation pouvaient potentiellement s’appliquer à un ensemble plus large de connaissances produites par les êtres humains. Barnes et Bollinger (1991) écrivent à cet égard : 

“La caractéristique déterminante d’une bonne réutilisation de la connaissance n’est pas la réutilisation d’un logiciel per se, mais la réutilisation des méthodes de résolution de problèmes inventées par les humaines ”

Autre élément permettant de renforcer cette hypothèse, Frakes et Isoda ont  établi les types de connaissances pouvant être réutilisés (ci-dessous) et parmi eux figurent des bases de données et des artefacts.  
- Descriptions de problèmes
- Arterfacts
- Proposition de projets
- Rapports de faisabilité
- Modèles d’entreprises 
- Dictionnaires de données 
- Prototypes
- Tables de décisions
- Pseudocodes
- Codes sources
- Bases de données 
- Connaissances tacites des développeurs
- Réseaux de développeurs. 

**Les barrières face à la réutilisation des données ouvertes**

Si Ruppert (2013) considèrent que les principales barrières à l’utilisation des données ouvertes par les citoyens sont principalement de l’ordre technique (manque d’équipement) et de la connaissance (en statistiques ou data-science), Ruijer et al. (2017) distingue 4 catégories de barrières qu’il regroupe en 2 dimensions. 

<table>
<thead>
<tr>
<th>Dimensions</th>
<th>Catégories</th>				
</tr>
</thead>
<tbody>
<tr>
<td rowspan= "2">Culturelle</td>
<td>Intérêt et connaissance</td>
</tr>
<tr>
<td>Valeur et qualité d’usage des données</td>
</tr>
<tr>
<td rowspan= "2">Structurelle</td>
<td>Accès aux données</td>
</tr>
<tr>
<td>Technique</td>
</tr>
</tbody>
</table>


Les barrières culturelles sont inhérentes à la nature de la donnée qui nécessite d’avoir acquis certaines compétences avant de pouvoir comprendre son intérêt et sa valeur. Contrairement au mythe des débuts de l’Open-data qui affirmait que tout un chacun pourrait directement utiliser les données, il faut maîtriser certaines techniques statistiques et d’autres connaissances pour pouvoir analyser les données, leur donner du sens et comprendre les implications que son utilisation peut avoir (Janssen, Charalabidis & Zuiderwijk, 2012). 

Les barrières structurelles relèvent principalement des imperfections des démarches d’ouverture des données. L’accès aux données est souvent rendu difficile par le manque de méta-données qui qualifient les jeux ouverts et permettent de les référencer au mieux sur les moteurs de recherche. Ainsi, toute personne intéressée par un jeu de donnée, passera un temps important à parcourir de nombreuses plateformes indépendante à la recherche de ce dernier, au risque de se décourager. Ce travail de production des métadonnées revient dans la plupart des cas au diffuseur de la donnée, et dans le cas de l’Open data, aux collectivités publiques. Or, ce travail est rarement effectué du fait du manque de moyen de ces dernières (Braunschweig et al., 2012)

Grâce à des entretiens menés auprès de développeurs, premiers utilisateurs de l’Open data, Le Corf (2016) montre les implications que peuvent avoir des barrières culturelles et structurelles trop difficiles à surmonter sur la dynamisme des projets de réutilisations
Selon son analyse , les barrières culturelles sont à l’origine de l’absence de modèle économique permettant de commercialiser les applications développées mais aussi de modèle de rémunération des développeurs qui permettrait de garantir la pérennité des services créés. Les barrières structurelles sont quant elles la cause du cantonnement des pratiques d’innovation auprès “d’innovateurs disposant de compétences techniques pointues”, ce qui pose un véritable problème dans le développement de services à valeur ajoutée pour l’utilisateur. En effet, c’est aux carrefours de différentes compétences que de nouveaux services fiables d’un point de vue technique et ergonomiques pourront voir le jour. 

Conclusion et transition | 
------------ | 
Après avoir fait état de la difficulté de réutiliser les données ouvertes pour créer de nouveaux services, il s’agit dans cette sous-partie de montrer qui sont les acteurs qui arrivent, malgré ces barrières, à innover. Je solliciterai 2 cadres théoriques qui viendront soutenir cet argument selon lequel la dynamique d’innovation de service issue de l’open est restreinte et réservée à un cercle de spécialiste.| 

**Une dynamique d’innovation de service restreinte et réservée à un cercle de spécialistes : l’absence de communautés de réutilisateurs de l’open data**

- L’open data à l’origine de publics et non de communautés

Pour Goëta et Denis (2013), l’ouverture des données brutes des administrations et les dispositifs qui incitent à leur utilisation apparaissent “comme des moteurs de la reconfiguration non seulement de l’Etat (...) mais aussi des citoyens, instaurés en public du gouvernement et de ses données”. Selon l’ancien Premier Ministre britannique David Cameron, en créant un nouveau lien avec les citoyens, l’open data reconfigure le rôle de l’Etat qui perdra le monopole des données et de leurs interprétations. Les citoyens pourront désormais intervenir dans le processus. 

Or, peu de personnes sont véritablement équipées pour dialoguer avec les gouvernements. Seuls les individus possédant les connaissances et équipements nécessaires pour interpréter des millions de tétrabytes de données le sont (Ruppert, 2013). Ces professionnels de la data sont le premier public qui va pouvoir interagir avec le gouvernement et qui va devenir le coeur des écosystèmes Open data. A l’inverse, les citoyens seront présents mais aux marges de ces écosystèmes étant donné leur faible niveau d’accoutumance à la culture de la donnée. Le Corf (2016) rejoint cette analyse en affirmant : “les développeurs web sont des publics cibles de ces actions d’intelligence territoriales qui s’accompagnent d’un discours communicationnel en faveur de la montée du paradigme de co-production comme en témoigne la multitude de formules visant à qualifier de nouveaux projets de gestion publique locale : Open data, smart cities, innovation ouverte et sociale, etc.”
Dès lors, ces écosystèmes sont d’abord constitués des services publics des Smart City qui fournissent les données; ensuite par les développeurs et les professionnels de l’informatique qui traitent la donnée et dont l’avis est pris en compte pour modifier la structure des données libérées ; et finalement, celui du citoyen qui utilisent les données, ses réutilisations et transformations. 

Cette analyse contraste avec une des grandes promesses de l’Open data qui devait faire émerger de nouvelles formes de gouvernements, plus transparents, plus responsables et plus à l’écoute de leurs administrés, gouvernements que l’on rassemble sous l’anglicisme d’Open government (Commission européenne, 2010). Hormi quelques rares exemples, les collectivités publiques n’ont pas mis en place des mécanismes de feedback permettant un dialogue entre les gouvernants et les gouvernés pouvant aboutir à l’émergence d’Open governments. En effet, de tels mécanismes impliquent une transformation profonde des institutions publiques au niveau organisationnel (Akrab, 2016) et culturel que les institutions n’ont pas encore menées à terme. La théorie des systèmes est souvent utilisée pour expliquer cette transformation : l’ouverture des données et la mise en place d’espaces de dialogues revient à faire passer les collectivités d’un mode de fonctionnement correspondant à celui d’un système fermé vers un autre correspondant à un système ouvert. Un système fermé est facile à diriger car il n’est pas influencé par des facteurs extérieurs, instables. On peut d’ailleurs utiliser des processus de contrôle rigides de ce fait. A l’inverse, un système ouvert ne peut être contrôlé de façon aussi précise du fait de l’intrusion de nouveaux éléments, dont l’intégration a des effets difficiles à prévoir. Dès lors, le passage d’un système ouvert à un système fermé nécessite de passer d’une logique de contrôle mécaniciste à une perspective évolutiste dominé par l’auto-organisation et son caractère imprévisible. Un passage difficile quand l’on considère l’aversion au risque historique des institutions publiques (Janssen, Charalabidis & Zuiderwijk, 2012)

- L’absence de communautés autour de l’open data expliquée par le cadre théorique du middleground (Cohendet et al., 2014) : les ré-utilisateurs comme acteurs marginaux dépourvus de moyens de transfert de leurs idées radicales en innovation 

Le cadre théorique du middleground s’inscrit dans les lignées des travaux en sociologie s’intéressant à la promotion des idées radicalement nouvelles (Becker, 1963 ; Coser, 1965 ; Merton, 1968). Il poursuit ce champs de recherche en introduisant le concept de communauté épistémique qui permet de faire le lien entre les acteurs marginaux et réalités économiques de l’innovation. Le concept de communauté épistémique reprend et adapte la définition d’une communauté selon Adler (1992) : “un réseau de professionnels avec une expertise reconnus, des compétences dans un domaine particulier et un positionnement politique”. Une communauté épistémique se définit alors comme : “un petite groupe d’agents créateurs de connaissances engagées sur un ensemble restreint de questions et qui acceptent et reconnaissent une autorité établie collectivement comme un des facteurs de succès des activités collectives” (Cowan et al., 2000, p.234)

Ces communautés épistémiques réalise un travail cognitif particulier que l’on peut comprendre comme une séquence de 4 étapes dont les 3 premières constituent des conditions nécessaires sans lesquelles aucune idée ne peut être transformé en innovation radicale : 

Créer un manifeste dans lequel sont inscrites les règles à respecter au cour du travail cognitif de la communauté
Construire un “codebook” qui précise les codes, normes et pratiques à respecter par les membres de la communauté
Attirer et convaincre d’autres acteurs de l’utilité et du potentiel du projet porté par cette communauté épistémique. 
Renforcement de la construction cognitive de la communauté par une exposition aux critiques, des interactions, des frictions et des désaccords avec d’autres communautés. 

Selon Cohendet et al. (2014), ces rencontres entre différentes communautés se font majoritairement dans des contextes locaux à travers des middleground qui, même en cas de dispersion géographique de la communauté, reste un point de passage obligé des processus cognitifs développés par la communauté. 

Ce point de passage se subdivise en 3 différentes couches que sont l’upperground, le middleground et l’underground (Figure ci-dessous) 

![Middleground](http://opendatatales.com/wp-content/uploads/2020/03/Screen-Shot-2020-03-02-at-11.59.29.png)
##### Figure 9 : les 3 couches d’un territoire selon l’approche du middleground. Source : Cohendet et al. (2014)

Tout d’abord, dans la couche underground, les idées radicales s’échangent à un niveau micro et migrent vers une échelle macro à travers l’accumulation, la combinaison, l’enrichissement et le renouvellement de bits d’informations dispersés sur le territoire. Ces dynamiques sont ensuite encouragées par une couche intermédiaire, le middleground qui facilite les relations entre l’underground et l’upperground. L’idée centrale de l’ouvrage de Cohendet et al. (2014) est que ce middleground accélère la dynamique des mouvements radicalement nouveaux qui ont besoin d’un processus cognitif de constructions d’idées cadré à mettre en place. Chacune des étapes de ce processus nécessite un milieu local fertile offrant des opportunités pour l’hybridation, la traduction, l’exposition aux critiques ou l’ouverture au monde extérieur. 

Le cadre théorique du middleground est né pour venir combler un manque dans la connaissances des processus de création de nouvelles connaissances et d’innovation. La littérature économique et géographique sur le sujet s’était jusque là accordé sur le fait que la concentration de ressources et compétences dans un périmètre local favorise la formation d’externalités de connaissances et stimule l’apprentissage et l’innovation. Or, Cohendet et al. (2014) ont mis en évidence que ce prisme d’analyse ne peut expliquer les mécanismes à l’origine des innovations radicales dans les milieux artistiques (l’avènement du cubisme par exemple), scientifiques (l’invention des machines à commande numérique par Von Neumann en 1942 par exemple) et technologiques (nous déterminerons dans une autre partie si l’open data peut se ranger dans la catégorie des innovations technologiques radicales). 
	
La première limite pointée par Cohendet et al. (2014) concerne le périmètre restreint des acteurs pris en compte dans l’étude des formations d’externalités de connaissances. Ce périmètre exclus notamment “les agents non-économiques aux idées déviantes”, ce qui constitue pour les auteurs un paradoxe puisqu’il a été démontré que ces acteurs ont été à l’origine de plusieurs innovations radicales. Nous rangeons dans cette catégorie ce que Townsend (2013) nomme les communautés “civic hackers” présentes dans les smart cities. Ce parallèle se justifie par le fait que ces communautés se sont rassemblées autour des idées utopiques et radices d’une société plus ouverte, transparente et horizontale, avant de promouvoir, hors de tout intérêt économique les technologies fondatrices des smart cities comme les applications mobile ou les capteurs open-source. 
	
L’exclusion des ces acteurs de l’étude classique des mécanismes de formation d’externalités de connaissance est ce qui explique que peu d’études se sont intéressées aux interactions nécessaires entre ces agents et les milieux établis pour transformer ces idées radicales en innovation : “little is said on how these agents (could) possibly find the complementary social, cognitive, organisational and institutional support needed for them (non-economic actors) to bring their most deviant ideas to the market” (p.933). On retrouve chez Kuk et Davies (2011) le constat similaire derrière leur étude des mécanismes de complémentarité permettant de transformer l’open data en services qui sont utilisés par les hackers. Ils affirment que peu d’études se sont intéressées aux activités menées par ces agents dans le cadre de leur engagement pour la libre utilisation des données produites par les acteurs publiques. Un engagement plus motivé par les défis intellectuels qu’il sous-tend et le plaisir liés à la résolution de problèmes difficiles qu’à la création d’un logiciel ou d’un service avec l’espoir de gains économiques (Laklani et Wolf, 2003). 
	
Ce peu d’études sur la transformation des idées radicales de l’open data en innovation est d’autant plus criant si l’on dresse une analogie avec les communautés du logiciel open-source : si les libristes et les mécanismes de ré-utilisation de codes permettant de créer les logiciels libres sont aujourd’hui compris et fortement documenté, peu de chercheurs se sont penchés sur la transformation en innovation des idées radicales derrières l’open data. Cette absence d’études peut facilement s’expliquer par la relative nouveauté de l’open data en tant que mouvement politique et idéologie (Chignard, 2013). Rappellons que les premières revandications pour une ouverture des données ne remontent qu’à 2007 avec la tenue de la conférence de Sebastopol à l’origine des principes qui définissent ce qu’est l’ouverture des données publiques. 

Cohendet et al. (2014) laissent la porte ouverte à la critique sur la question de la nécessaire centralisation géographique des communautés épistémiques en prenant acte du potentiel grandissant des plateformes virtuelles. Il reconnaît que les contextes virtuels favorisent certainement le travail cognitif des membres d’une seule communauté mais doute qu’ils puissent stimuler les interactions entre plusieurs communautés, interactions nécessaires par ailleurs à la transformation en innovation des outputs de chacune d’entre elles. 
Cette thèse s’engouffre précisément dans cette ouverture puisque nous avançons que les communautés open data se développent dans de multiples contextes géographiques de fait de l’ubiquité intrinsèque des données et des interactions nécessaires à la transformation des données en innovations qui dépassent et transcendent les frontières géographiques. 


- L’absence de communautés autour de l’open data expliquée par la théorie des biens communs : un commun libertarien qui rend impossible l’existence d’une communauté

Une autre façon d’expliquer l’absence d’une communauté de réutilisateurs sollicite la distinction établie par Levine (2007) entre les communs libertariens et les communs associatifs. Les communs libertariens sont des communs auxquels tout le monde a accès et que tout le monde peut utiliser et auxquels tout le monde peut contribuer. Les océans sont par exemple des biens communs libertariens. Les communs associatifs sont eux contrôlés par un groupe qui a le droit et le pouvoir de limiter son accès, son utilisation et sélectionner les contributions. Levine prend les églises et autres bâtiments détenus par certaines congrégations religieuses. En parallèle de l’accueil de concerts et de touristes à titre gracieux, la congrégation donné accès à certains espaces et événements aux personnes qui acceptent de payer une redevance qui est réinjectée pour financer les travaux sur les bâtiments en cas de dégradation. 

Si l’on se rappelle la loi pour une République numérique qui fixe le principe d’ouverture par défaut des données des administrations et ce, “dans un standard ouvert, aisément réutilisable et exploitable par un système de traitement automatisé’ (article L.300-4), on conviendra qu’il n’existe alors aucun droit de restriction à l’accès aux données ouvertes et donc qu’elles correspondent à des communs libertariens. Or, Levine avance que les communs libertariens, bien qu’ils possèdent l’attrait de l’accès inconditionnel, souffrent du problème du passager clandestin et de l’impossibilité d’être protégé de la dégradation ou des phénomènes d’enclosures. Prenons l’exemple des informations et connaissances qui circulent sur Internet. Tandis que tout individu peut aujourd’hui produire ou utiliser des informations sur Internet, ce libre accès laisse la porte ouverte aux fake news, à des formes d’influences et de récupérations politiques. En face, les défenseurs d’Internet et de la libre circulation des informations et connaissances se trouvent dans une situation d’impuissance puisqu’un acteur “n’a intérêt à payer pour défendre un bien dont tout le monde par ailleurs béneficie” (Levine, 2007, p252). 

Cette situation propre aux communs libertariens est une façon d’expliquer pourquoi il n’existe pas de communauté de réutilisateurs au sens entendu par la théorie des biens communs. L’accès des données étant ouvert à tous, aucun réutilisateur ni aucune organisation n’a intérêt à se positionner comme défenseur de celles-ci et à supporter les coûts liés à la gestion d’une communauté de réutilisateurs. 

Conclusion et transition | 
------------ | 
Après recensé les cadres théoriques permettant de justifier l’argument selon lequel l’open data ne s’adresse pas au plus grand nombre mais plutôt à un catégorie d’acteurs bien dotées en ressources et compétences, je m’attacherai dans cette partie à démontrer qu’en plus d’être restreinte à petit groupe d’acteurs, l’innovation de services issues de l’open data est difficilement observable par les méthodes classiques de recherche. Le travail de transformation de l’open data en innovation est un phénomène invisible, se déroulant sous les radars de la plupart des acteurs de la smart city.| 

**Une dynamique d’innovation de service invisible et désordonnée : l’absence de schéma et de règles de gouvernance des données ouvertes**

- Ouverture des données et anonymat : les raisons du manque de connaissance des parties prenantes de l’open data

Les utilisateurs des jeux de données ouvertes sont aujourd’hui peu connus des administrateurs de plateformes Open data du fait qu’un traceur n’est installé sur les jeux de données lorsqu’ils sont téléchargés ou bien aspirés via les APIs disponibles. Or, ce manque de connaissance sur l’identité des utilisateurs s’accompagne d’un manque de connaissances sur les attentes de ces utilisateurs vis à vis des jeux de données, ce qui devient problématique lorsque les collectivités territoriales souhaitent stimuler l’usage des jeux de données dans le cadre de démarches d’innovations. En effet,  l’innovation étant la résultante de la rencontre d’une technologie disponible et d’un besoin recensé (Schon, 1967), il est difficile de stimuler l’innovation quand on ne sait pas qui sont les personnes ayant besoin des données et la nature de ce besoin. 

Ironiquement, cette zone d’ombre devenue barrière était au coeur de l’esprit originel de l’Open data. L’hypothèse de base de la démarche était qu’une fois les données libérées, référencées et disponibles dans plusieurs formats et sous des licenses permettant leur réutilisation, les innovations se créeraient d’elles-mêmes. Face au constat de la faible utilisation des données ouvertes, nous pouvons dire que cette hypothèse relève, dans le meilleur des cas, d’un excès d’optimisme ou, dans le pire, de la contradiction. Ruijer et al. (2017) s’accordent sur la deuxième option lorsqu’ils écrivent : “en réalité cette hypothèse perturbe l’usage des données car elle implique un écart entre les besoins contextualisés d’un utilisateur et l’offre de données”. Autrement dit, les démarches Open data telles qu’elles ont été conçues initialement éloignent plus qu’elles ne rapprochent l’échéance à laquelle le potentiel de transformation économique de l’Open data se réalisera. 

- Les tentatives d’identification des parties prenantes de l’open data dans la littérature

Dans sa thèse, Zuiderwijk (2015) distingue 3 types de membres :  les fournisseurs de données ouvertes, les utilisateurs de données ouvertes et les décideurs. Les fournisseurs de données ouvertes comprennent les agences gouvernementales qui produisent ou collectent de grandes quantités de données afin de remplir leurs tâches quotidiennes et les organisations financées par des fonds publics qui produisent et collectent des données au nom d'agences gouvernementales. Nous rajoutons à cette catégorie l’ensemble des acteurs civils et privés qui possèdent des données relevant de l’intérêt général et qui les rendent accessibles librement et gratuitement. 

Une fois les données ouvertes libérées, les utilisateurs de données ouvertes entrent en jeu pour réutiliser les données : ces utilisateurs proviennent de différents contextes et utilisent des données à de nombreuses fins. Néanmoins, on peut noter qu’ils ont un objectif commun : transformer la donnée en information actionnable puis, pour certain, en connaissances qu’ils transmettent ensuite aux décideurs. 
Les décideurs utilisent les information et/ou connaissances générées grâce aux données ouvertes comme intrants pour formuler leurs décisions. Dans le cadre de cette thèse, nous restreindrons cette catégorie aux fournisseurs de services publics dans les Smart Cities.



Gascò-Hernàndez et al. (2018) s’est concentré sur les utilisateurs de l’open data. Il distingue 4 types d’utilisateurs :

- les fonctionnaires qui utilisent les données publiques pour améliorer les services publics autant que les processus de prise de décision. 
- les innovateurs, parmi lesquels nous retrouvons les développeurs informatiques et les entreprises, utilisent les données dans une optique de créer des nouveaux produits ou services innovants pour les commercialiser. 
- les chercheurs, data-journalistes et activistes utilisent pour leur part l’Open data dans le but de créer de la connaissance sous différents formats
- les citoyens utilisent utilisent généralement les données indirectement via certains médiateurs qui traduisent les données. 


#### Les 3 générations de plateformes Open Data

- PhD Working Book (4) - p. 101-102 - Faible performance des plateformes de deuxième génération  
- PhD Working Book (1) - Plateformes de deuxième génération - Alewopoulos et al. (2014) - p.34
- PhD Working Book (8) - p.47 - Plateformes de collaboration (Hogan, 2017)
- PhD Working Book (9) - p.364 - Application du concept de plateforme auto-poietique


#### Innovation de services 

- PhD Working Book (7) - p.55-57/60-63 - Premier mindmap sur la littérature "classique" sur l'innovation de services
- PhD Working Book (2) - p.20-24 - Perspectives sur l'innovation de services
- Conclusion sur le centrage autour du schéma d'assemblage de Kuk et Davies (2011) + petits mains de l'open data et études STS (Denis) + PhD Working Book (2) - p.24-26 - Différentes descritpions des interactions en jeu dans l'innovation de services + PhD Working Book (3)- p.16-19 précisions feedback & collaboration 
- PhD Working Book (7) - p.154-159 - Centrer innovation de services autour de la relation de service (Denis et Pontille, Travalleurs de l'écrit, matières de l'information)
- PhD Working Book (8) - p.1-4 Couture (2012) - Suite sur la définition et la nature de l'OD Work
- PhD Working Book (8) - p.16 - Première mention de la Cognitive Work Analysis pour modéliser l'OD Work
- PhD Working Book (7) - Référence à Boutet (2001) avec exemple d'une relation de service et de la place des données 
- PhD Working Book (3) - p.58-66 - La réutilisation ou l'autre nom de l'innovation
- PhD Working Book (5) - p.57-58 - Démonstration de la différence entre l'utilisation et la réutilisation
- PhD Working Book (5) - p.116 et 119 -  Jetzek et al.(2014) OGD data-driven innovation mechanisms - Autre modèle d'innovation
- PhD Working Book (5) - p.137-141 - Carrara et al. (2015) - Valeurs créées par l'open data (cf data-driven innovation mechanisms)


Conclusion et transition | 
------------ | 
Dans cette partie, | 





