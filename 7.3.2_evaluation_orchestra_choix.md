# 7. Quasi-expérimentations visant à évaluer la capacité d'Innodata à faciliter les interactions entre les opérateurs de l'open data et les *data spaces*

## 7.3.1 Rappel des caractéristiques du prototype et de la question de recherche à laquelle les quasi-expérimentations répondent : un artefact de meta-design formatif pour orchestrer les interactions opérateurs-data space

## 7.3.2 Le protocole d'évaluation mis en oeuvre : terrain et récolte de données 

### 7.3.2.1 Analyse de l'évaluation

<table>
    <thead>
        <tr>
            <th>Critères à évaluer</th>
            <th>Altervatives possibles </th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>Forme</td>
            <td><ul><li>[ ] Concept</li><li>[ ] Modèle</li><li>[ ] Méthode</li><li>[ ] Instance</li><li>[ ] Théorie</li></ul>
        </td>
        <tr>
            <td>Nature</td>
            <td><ul><li>[ ] Produit/Technique</li><li>[ ] Process/Socio-technique</li></ul>
        </td>
        <tr>
            <td>Propriété(s) à évaluer</td>
            <td><ul><li>[ ] Utilité</li><li>[ ] Efficacité</li><li>[ ] Efficience</li><li>[ ] Qualité</li><li>[ ] Théorie</li></ul>
        </td>
        <tr>
            <td>Objectif(s) de l'évaluation</td>
            <td><ul><li>[ ] Artefact = atteinte des objectifs</li><li>[ ] Artefact = avantage comparatif</li><li>[ ] Artefact = évaluation des effets collatéraux et conséquences inattendues</li></ul>
        </td>
        <tr>
            <td>Contraintes de l'environnement (ressources)</td>
            <td><ul><li>[ ] Temps limité</li><li>[ ] Compétences limitées</li><li>[ ] Budget limité</li><li>[ ] Accès au terrain limité</li><li>[ ] Théorie</li></ul>
        </td>
        <tr>
            <td>Rigueur à appliquer</td>
            <td><ul><li>[ ] Faible ("On juge un arbre à ses fruits")</li><li>[ ] Forte (contrôle des variables)</li></ul>
        </td>
        <tr>
            <td>Pondération</td>
            <td><ul><li>[1] Forme</li><li>[1] Nature</li><li>[1] Propriété(s)</li><li>[1] Objectif(s)</li><li>[1] Contraintes de l'environnement</li><li>[1] Rigueur à appliquer</li></ul>
        </td>
    </tbody>
</table>

### 7.3.2.2 Choix d'une stratégie

<table>
    <thead>
        <tr>
            <th colspan=2 rowspan=2>Framework de Selection des Stratégies d'Evaluation</th>
            <th>Ex ante </th>
            <th>Ex post </th>
        </tr>
    </thead>
    <tbody>
      <tr>
            <td></td>
            <td></td>
            <td><ul><li>[ ] Evaluation formative</li><li>[ ] Cout moins élevé</li><li>[ ] Plus rapide</li><li>[ ] Evaluation du design, d'un protoype partiel ou complet</li><li>[ ] Moins de risque pour les participants durant l'évaluation</li><li>[ ] Risque plus élevé de faux positifs</li></ul></td>
            <td><ul><li>[ ] Evaluation sommative</li><li>[ ] Cout plus élevé</li><li>[ ] Moins rapide</li><li>[ ] Evaluation des instances</li><li>[ ] Plus de risques pour les participants durant l'évaluation</li><li>[ ] Risque moins élevé de faux positifs</li></ul></td>
        </tr>
        <tr>
            <td>Naturaliste</td>
            <td><ul><li>[ ] Plusieurs parties prenantes hétérogènes</li><li>[ ] Conflits substantiels</li><li>[ ] Artefacts socio-technique</li><li>[ ] Cout plus élevé</li><li>[ ] Evaluation longue</li><li>[ ] Accès au terrain requis</li><li>[ ] Evaluation de l'utilité de l'artefact</li><li>[ ] Niveau de rigueur : "On juge l'arbre à ses fruits"</li><li>[ ] Risque plus élevé pour les participants</li><li>[ ] Risque de faux positif plus faible</li></td>
            <td><ul><li>Utilisateurs réels, problèmes réels et système irréel</li><li>Cout faible-moyen</li></ul><ul><li>Vitesse correcte</li><li>Risque faible pour les participants</li><li>Risque élevé de faux positifs</li></ul></td>
            <td><ul><li>Utilisateurs réels, problèmes réels et systèmes réels</li><li>Cout le plus élevé</li><li>Risque le plus élevé pour les participants</li><li>Meilleure évaluation de l'utilité</li><li>Identification des effets collatéraux</li><li>Risque le moins élevé de faux positifs</li></ul></td>
        </tr>
        <tr>
            <td>Artificielle</td>
            <td><ul><li>[ ] Peu de parties prenantes similaires</li><li>[ ] Peu ou pas de conflits</li><li>[ ] Artefacts purement techniques</li><li>[ ] Cout moins élevé</li><li>[ ] Evaluation courte</li><li>[ ] Niveau de rigueur : contrôle des variables</li><li>[ ] Evaluation de l'efficacité </li><li>[ ] Risque moins élevé pendant l'évaluation</li><li>[ ] Risque de faux positif plus élevé</li></ul></td>
            <td><ul><li>Utilisateurs irréels, problèmes irréels et système irréels</li><li>Cout le moins élevé</li></ul><ul><li>Vitesse la plus élevée</li><li>Risque le moins élevé pour les participants</li><li>Risque le plus élevé de faux positifs</li></ul></td>
            <td><ul><li>Système réel, problème iréel et utilisateurs irréels</li><li>Cout moyen/élevé</li></ul><ul><li>Vitesse correcte</li><li>Risque faible-moyen pour les participants</li></ul></td>
        </tr>
    </tbody>
</table>

### 7.3.2.3 Choix de la méthode 

### 7.3.2.4 Design du détail de l'évaluation 
